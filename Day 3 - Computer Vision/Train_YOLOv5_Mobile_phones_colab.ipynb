{"cells":[{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["# How to Train YOLOv5 on Custom Objects\n","\n","This tutorial is based on the [YOLOv5 repository](https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/). This notebook shows training on **your own custom objects**. \n","\n","### Accompanying Blog Post\n","\n","We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv5](https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/), and [how to train YOLOv5 with deployment to web camera](https://blog.paperspace.com/train-yolov5-custom-data/#set-up-the-code) concurrently.\n","\n","### Steps Covered in this Tutorial\n","\n","In this exercise, we will walk through the steps required to train YOLOv5 on your custom objects. We use a private, AAU-made dataset containing parts of a mock-up mobile phone from our AAU Smart Production Lab.\n","\n","The dataset is already uploaded on Roboflow (as we have seen during the lecture) but you can also download it from PhD moodle (make sure you are already logged in there) to use in your local environment.\n","\n","[Download the dataset from AAU PhD moodle here](https://phd.moodle.aau.dk/mod/resource/view.php?id=18660)\n","\n","In the exercise here, we use the dataset directly from Roboflow. \n","\n","The dataset is free to use for the needs of the course. However, please do not share the dataset with others. \n","\n","You can also use this notebook on your own custom data.\n","\n","To train the detector we take the following steps:\n","\n","* Install YOLOv5 dependencies\n","* Download custom YOLOv5 object detection data\n","* Write our YOLOv5 Training configuration\n","* Run YOLOv5 training\n","* Evaluate YOLOv5 performance\n","* Visualize YOLOv5 training data\n","* Run YOLOv5 inference on test images\n","* Export saved YOLOv5 weights for future inference\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbvMlHd_QwMG"},"outputs":[],"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.downloads import attempt_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ie5uLDH4uzAp"},"outputs":[],"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"]},{"cell_type":"markdown","metadata":{"id":"SDIhrBF0sPaM"},"source":["# Download Correctly Formatted Custom Dataset \n","\n","We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n","\n","To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."]},{"cell_type":"markdown","metadata":{"id":"vDeebwqS9JbZ"},"source":["\n","\n","![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Knxi2ncxWffW"},"outputs":[],"source":["#follow the link below to get your download code from from Roboflow\n","!pip install -q roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ug_PhK1oqwQA"},"outputs":[],"source":["%cd /content/yolov5\n","#after following the link above, recieve python code with these fields filled in\n","#from roboflow import Roboflow\n","#!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"dFupJKhsuCbKRD4VEIR4\")\n","project = rf.workspace(\"cv-lecture\").project(\"cv-lecture-test\")\n","dataset = project.version(2).download(\"yolov5\")\n","\n","#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n","#project = rf.workspace().project(\"YOUR PROJECT\")\n","#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZ3DmmGQztJj"},"outputs":[],"source":["# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat {dataset.location}/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"UwJx-2NHsYxT"},"source":["# Define Model Configuration and Architecture\n","\n","We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n","\n","You do not need to edit these cells, but you may."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dOPn9wjOAwwK"},"outputs":[],"source":["# define number of classes based on YAML\n","import yaml\n","with open(dataset.location + \"/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Rvt5wilnDyX"},"outputs":[],"source":["#this is the model configuration we will use for our tutorial \n","%cat /content/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t14hhyqdmw6O"},"outputs":[],"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDxebz13RdRA"},"outputs":[],"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"]},{"cell_type":"markdown","metadata":{"id":"VUOiNLtMP5aG"},"source":["# Train Custom YOLOv5 Detector\n","\n","### Next, we'll fire off training!\n","\n","\n","Here, we are able to pass a number of arguments:\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** set the path to our yaml file\n","- **cfg:** specify our model configuration\n","- **weights:** specify a custom path to weights. (Note: you can download weights from our GitHub [folder](https://github.com/AAU-RoboticsAutomationGroup/PhDAppliedAIMecManEng/tree/main/Day%203%20-%20Computer%20Vision/trained_networks))\n","- **name:** result names\n","- **nosave:** only save the final checkpoint\n","- **cache:** cache images for faster training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1NcFxRcFdJ_O"},"outputs":[],"source":["# train yolov5s on custom data for 300 epochs (takes ~1hour, reduce to 100 epochs for ~20mins)\n","# time its performance\n","# Try changing\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 416 --batch 16 --epochs 300 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"]},{"cell_type":"markdown","metadata":{"id":"kJVs_4zEeVbF"},"source":["# Evaluate Custom YOLOv5 Detector Performance"]},{"cell_type":"markdown","metadata":{"id":"7KN5ghjE6ZWh"},"source":["Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n","\n","Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOy5KI2ncnWd"},"outputs":[],"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C60XAsyv6OPe"},"outputs":[],"source":["# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"]},{"cell_type":"markdown","metadata":{"id":"N3qM6T0W53gh"},"source":["#Run Inference  With Trained Weights\n","Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIEwt5YLeQ7P"},"outputs":[],"source":["# trained weights are saved by default in our weights folder\n","%ls runs/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SyOWS80qR32"},"outputs":[],"source":["%ls runs/train/yolov5s_results/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nmZZnWOgJ2S"},"outputs":[],"source":["# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n","# use the best weights!\n","%cd /content/yolov5/\n","!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.6 --source /content/yolov5/CV-lecture-test-2/test/images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"odKEqYtTgbRc"},"outputs":[],"source":["#display inference on ALL test images\n","#this looks much better with longer training above\n","\n","import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"_uPq9mVgiBql"},"source":["# Export Trained Weights for Future Inference\n","\n","Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YH4CTzDRh00g"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1x_wg3VeiXMW"},"outputs":[],"source":["%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My\\ Drive\n","#%cp -r /content/yolov5/ /content/gdrive/My\\ Drive/"]},{"cell_type":"markdown","metadata":{"id":"LVpCFeU-K4gb"},"source":["## That's all folks! \n","\n","Try with you own datasets and different settings!"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1669820074281},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}